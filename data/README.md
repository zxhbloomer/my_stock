# Data Module è®¾è®¡æ–‡æ¡£

## ğŸ“‹ æ•´ä½“æ¶æ„è®¾è®¡

æœ¬æ¨¡å—æ•´åˆäº†ç°æœ‰çš„ç®€å•é‡‡é›†å™¨æ¨¡å¼å’ŒalphaHomeçš„ä»»åŠ¡ç³»ç»Ÿæ¶æ„ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®è·å–å’Œå¤„ç†èƒ½åŠ›ã€‚

## ğŸ—ï¸ æ¨èç›®å½•ç»“æ„

```
data/
â”œâ”€â”€ __init__.py                          # æ¨¡å—å…¥å£ï¼Œç»Ÿä¸€å¯¼å‡º
â”‚
â”œâ”€â”€ common/                              # é€šç”¨ç»„ä»¶ï¼ˆä»alphaHomeå­¦ä¹ ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ task_system.py                   # ç»Ÿä¸€ä»»åŠ¡ç³»ç»Ÿï¼šBaseTask, TaskFactory, @task_register
â”‚   â”œâ”€â”€ logging_utils.py                 # æ—¥å¿—å·¥å…·
â”‚   â””â”€â”€ db_manager.py                    # æ•°æ®åº“ç®¡ç†å™¨ï¼ˆå¼‚æ­¥AsyncIOï¼‰
â”‚
â”œâ”€â”€ collectors/                          # æ•°æ®é‡‡é›†å™¨æ¨¡å—ï¼ˆå¤–éƒ¨API â†’ æœ¬åœ°å­˜å‚¨ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fetcher_task.py             # æŠ½è±¡é‡‡é›†ä»»åŠ¡åŸºç±»ï¼ˆ3ç§æ›´æ–°æ¨¡å¼ï¼šMANUAL/SMART/FULLï¼‰
â”‚   â”‚   â””â”€â”€ collector.py                # å…¼å®¹æ—§ç‰ˆbase_collector.pyçš„ç®€åŒ–ç‰ˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ sources/                         # æ•°æ®æºå®ç°
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tushare/                    # Tushareæ•°æ®æº
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tushare_task.py         # Tushareä»»åŠ¡åŸºç±»ï¼ˆé›†æˆAPIå®¢æˆ·ç«¯å’Œè½¬æ¢å™¨ï¼‰
â”‚   â”‚   â”‚   â”œâ”€â”€ tushare_api.py          # Tushare APIå®¢æˆ·ç«¯ï¼ˆå«é€Ÿç‡é™åˆ¶ã€åˆ†é¡µã€å¹¶å‘æ§åˆ¶ï¼‰
â”‚   â”‚   â”‚   â”œâ”€â”€ tushare_collector.py    # å…¼å®¹æ—§ç‰ˆçš„Runç±»ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
â”‚   â”‚   â”‚   â””â”€â”€ data_transformer.py     # æ•°æ®è½¬æ¢å™¨ï¼ˆåˆ—æ˜ å°„ã€æ—¥æœŸè½¬æ¢ã€è‡ªå®šä¹‰å˜æ¢ï¼‰
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ qlib/                       # Qlibå®˜æ–¹æ•°æ®æºï¼ˆæœªæ¥æ‰©å±•ï¼‰
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ qlib_collector.py
â”‚   â”‚
â”‚   â””â”€â”€ tasks/                          # å…·ä½“é‡‡é›†ä»»åŠ¡ï¼ˆæŒ‰èµ„äº§ç±»åˆ«ç»„ç»‡ï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ stock/                      # è‚¡ç¥¨æ•°æ®é‡‡é›†
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ daily_bar.py           # æ—¥çº¿è¡Œæƒ…é‡‡é›†ä»»åŠ¡
â”‚       â”‚   â”œâ”€â”€ adj_factor.py          # å¤æƒå› å­é‡‡é›†ä»»åŠ¡
â”‚       â”‚   â”œâ”€â”€ index_weight.py        # æŒ‡æ•°æˆåˆ†å’Œæƒé‡
â”‚       â”‚   â””â”€â”€ basic_info.py          # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
â”‚       â”‚
â”‚       â”œâ”€â”€ fund/                       # åŸºé‡‘æ•°æ®é‡‡é›†
â”‚       â”œâ”€â”€ index/                      # æŒ‡æ•°æ•°æ®é‡‡é›†
â”‚       â””â”€â”€ macro/                      # å®è§‚æ•°æ®é‡‡é›†
â”‚
â”œâ”€â”€ processors/                         # æ•°æ®å¤„ç†å™¨æ¨¡å—ï¼ˆæ•°æ®åº“ â†’ ç‰¹å¾å·¥ç¨‹ â†’ æ•°æ®åº“ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ processor_task.py          # å¤„ç†ä»»åŠ¡åŸºç±»ï¼ˆå•è¡¨/å¤šè¡¨æŸ¥è¯¢ï¼Œä¾èµ–æ£€æŸ¥ï¼‰
â”‚   â”‚   â”œâ”€â”€ block_processor.py         # åˆ†å—å¤„ç†Mixinï¼ˆå¤§æ•°æ®é›†åˆ†å—å¤„ç†ï¼‰
â”‚   â”‚   â””â”€â”€ normalizer.py              # å…¼å®¹æ—§ç‰ˆçš„DataNormalizerç±»
â”‚   â”‚
â”‚   â”œâ”€â”€ operations/                     # æ•°æ®å¤„ç†æ“ä½œï¼ˆå¯ç»„åˆçš„æ“ä½œå•å…ƒï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_operation.py          # æ“ä½œåŸºç±»å’Œæ“ä½œæµæ°´çº¿
â”‚   â”‚   â”œâ”€â”€ missing_data.py            # ç¼ºå¤±å€¼å¤„ç†ï¼ˆFillNAOperation, DropNAOperationï¼‰
â”‚   â”‚   â”œâ”€â”€ technical_indicators.py    # æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼ˆMA, RSI, MACDç­‰ï¼‰
â”‚   â”‚   â””â”€â”€ data_cleaning.py           # æ•°æ®æ¸…æ´—æ“ä½œ
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                          # å¤„ç†å·¥å…·
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ query_builder.py           # SQLæŸ¥è¯¢æ„å»ºå™¨ï¼ˆå‚æ•°åŒ–ã€é˜²æ³¨å…¥ï¼‰
â”‚   â”‚   â”œâ”€â”€ data_validator.py          # æ•°æ®éªŒè¯å™¨ï¼ˆç±»å‹ã€èŒƒå›´ã€å¼‚å¸¸å€¼æ£€æµ‹ï¼‰
â”‚   â”‚   â””â”€â”€ validator.py               # å…¼å®¹æ—§ç‰ˆçš„ç®€åŒ–éªŒè¯å™¨
â”‚   â”‚
â”‚   â””â”€â”€ tasks/                          # å…·ä½“å¤„ç†ä»»åŠ¡
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ stock/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ adjusted_price.py      # åå¤æƒä»·æ ¼è®¡ç®—
â”‚       â”‚   â”œâ”€â”€ adjdaily_processor.py  # æ—¥çº¿å¤æƒ+äº¤æ˜“æ—¥è¡¥å…¨
â”‚       â”‚   â”œâ”€â”€ technical_features.py  # æŠ€æœ¯ç‰¹å¾è®¡ç®—
â”‚       â”‚   â””â”€â”€ fundamental_features.py # åŸºæœ¬é¢ç‰¹å¾è®¡ç®—
â”‚       â”‚
â”‚       â””â”€â”€ portfolio/                  # ç»„åˆæ•°æ®å¤„ç†
â”‚
â””â”€â”€ loaders/                            # æ•°æ®åŠ è½½å™¨ï¼ˆæœªæ¥é¢„ç•™ï¼Œç”¨äºQlib Handleré›†æˆï¼‰
    â”œâ”€â”€ __init__.py
    â””â”€â”€ qlib_loader.py
```

---

## ğŸ”„ è®¾è®¡åŸåˆ™

### 1. **æ¸è¿›å¼è¿ç§»ï¼ˆProgressive Migrationï¼‰**
- ä¿ç•™ç°æœ‰çš„ç®€å•æ¥å£ï¼ˆ`base_collector.py`, `tushare_collector.py`, `normalizer.py`, `validator.py`ï¼‰
- æ–°å¢é«˜çº§ä»»åŠ¡ç³»ç»Ÿï¼ˆ`fetcher_task.py`, `processor_task.py`ï¼‰
- ä¸¤å¥—ç³»ç»Ÿå…±å­˜ï¼Œé€æ­¥è¿ç§»æ—§ä»£ç åˆ°æ–°æ¶æ„

### 2. **èŒè´£åˆ†ç¦»ï¼ˆSeparation of Concernsï¼‰**
```
collectors/   â†’ å¤–éƒ¨æ•°æ®æº â†’ åŸå§‹æ•°æ®å­˜å‚¨ï¼ˆCSV/æ•°æ®åº“ï¼‰
processors/   â†’ æ•°æ®åº“ â†’ ç‰¹å¾å·¥ç¨‹ â†’ æ¨¡å‹è®­ç»ƒæ•°æ®
loaders/      â†’ æ•°æ® â†’ Qlib Handler â†’ æ¨¡å‹
```

### 3. **ç»Ÿä¸€ä»»åŠ¡ç³»ç»Ÿï¼ˆUnified Task Systemï¼‰**
```python
# æ‰€æœ‰ä»»åŠ¡ä½¿ç”¨ç»Ÿä¸€çš„è£…é¥°å™¨æ³¨å†Œ
@task_register()
class MyTask(FetcherTask):  # æˆ– ProcessorTask
    name = "my_task"
    # ...
```

### 4. **AsyncIOä¼˜å…ˆï¼ˆAsync-Firstï¼‰**
- æ‰€æœ‰æ–°ä»»åŠ¡ä½¿ç”¨ `async/await`
- å¹¶å‘æ§åˆ¶ï¼š`asyncio.Semaphore`
- é€Ÿç‡é™åˆ¶ï¼šæ»‘åŠ¨çª—å£ç®—æ³•

### 5. **å¯ç»„åˆæ“ä½œï¼ˆComposable Operationsï¼‰**
```python
# æ“ä½œæµæ°´çº¿ç¤ºä¾‹
pipeline = OperationPipeline("æ—¥çº¿å¤„ç†")
pipeline.add_operation(FillNAOperation(method='mean'))
pipeline.add_operation(MovingAverageOperation(window=5))
pipeline.add_operation(RSIOperation(window=14))
result = await pipeline.apply(data)
```

---

## ğŸ“¦ æ ¸å¿ƒç»„ä»¶è¯´æ˜

### A. ç»Ÿä¸€ä»»åŠ¡ç³»ç»Ÿï¼ˆcommon/task_system.pyï¼‰

#### BaseTaskï¼ˆæŠ½è±¡åŸºç±»ï¼‰
```python
class BaseTask(ABC):
    """æ‰€æœ‰ä»»åŠ¡çš„åŸºç±»"""
    task_type: str              # "fetch" æˆ– "processor"
    name: str                   # ä»»åŠ¡åç§°ï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
    description: str            # ä»»åŠ¡æè¿°
    dependencies: List[str]     # ä¾èµ–çš„å…¶ä»–ä»»åŠ¡

    @abstractmethod
    async def execute(self, **kwargs):
        """æ‰§è¡Œä»»åŠ¡çš„æ ¸å¿ƒé€»è¾‘"""
        pass
```

#### UnifiedTaskFactoryï¼ˆä»»åŠ¡å·¥å‚ï¼‰
```python
class UnifiedTaskFactory:
    """ç»Ÿä¸€ä»»åŠ¡å·¥å‚ï¼Œç®¡ç†æ‰€æœ‰æ³¨å†Œçš„ä»»åŠ¡"""
    _tasks: Dict[str, Type[BaseTask]] = {}

    @classmethod
    def register(cls, task_class):
        """æ³¨å†Œä»»åŠ¡ç±»"""
        cls._tasks[task_class.name] = task_class

    @classmethod
    def get_task(cls, name: str) -> BaseTask:
        """æ ¹æ®åç§°è·å–ä»»åŠ¡å®ä¾‹"""
        return cls._tasks[name]()
```

#### @task_registerè£…é¥°å™¨
```python
def task_register():
    """ä»»åŠ¡æ³¨å†Œè£…é¥°å™¨"""
    def wrapper(task_class):
        UnifiedTaskFactory.register(task_class)
        return task_class
    return wrapper
```

---

### B. æ•°æ®é‡‡é›†å™¨ï¼ˆcollectors/ï¼‰

#### FetcherTaskï¼ˆæŠ½è±¡åŸºç±»ï¼‰
```python
class FetcherTask(BaseTask, ABC):
    """æ•°æ®é‡‡é›†ä»»åŠ¡åŸºç±»"""

    # ä¸‰ç§æ›´æ–°æ¨¡å¼
    UPDATE_TYPE = Enum("UpdateType", ["MANUAL", "SMART", "FULL"])

    # æ ¸å¿ƒé…ç½®
    default_concurrent_limit = 5       # å¹¶å‘é™åˆ¶
    default_max_retries = 3            # é‡è¯•æ¬¡æ•°
    default_retry_delay = 2            # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    smart_lookback_days = 10           # SMARTæ¨¡å¼å›æº¯å¤©æ•°

    @abstractmethod
    def get_batch_list(self, **kwargs) -> List[Dict]:
        """ç”Ÿæˆæ‰¹æ¬¡åˆ—è¡¨ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass

    @abstractmethod
    async def fetch_batch(self, batch_params: Dict, stop_event=None):
        """è·å–å•ä¸ªæ‰¹æ¬¡æ•°æ®ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass

    async def _execute_batches(self, batches: List[Any], stop_event=None):
        """å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ‰¹æ¬¡ï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰"""
        semaphore = asyncio.Semaphore(self.concurrent_limit)
        # ... å¹¶å‘æ‰§è¡Œ + è¿›åº¦æ¡ + é‡è¯•
```

#### TushareTaskï¼ˆTushareä¸“ç”¨åŸºç±»ï¼‰
```python
class TushareTask(FetcherTask):
    """Tushareæ•°æ®æºä»»åŠ¡"""
    data_source = "tushare"
    default_page_size = 5000           # åˆ†é¡µå¤§å°
    default_rate_limit_delay = 65      # é€Ÿç‡é™åˆ¶é—´éš”

    def __init__(self, token: str, **kwargs):
        self.api = TushareAPI(token)
        self.data_transformer = TushareDataTransformer()

    async def fetch_batch(self, params: Dict, stop_event=None):
        """è°ƒç”¨Tushare APIå¹¶è½¬æ¢æ•°æ®"""
        data = await self.api.query(
            api_name=self.api_name,
            fields=self.fields,
            stop_event=stop_event,
            **params
        )
        return self.data_transformer.process_data(data)
```

#### TushareAPIï¼ˆAPIå®¢æˆ·ç«¯ï¼‰
```python
class TushareAPI:
    """Tushare HTTP APIå®¢æˆ·ç«¯"""

    # æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°ï¼ˆæŒ‰APIåˆ†ç±»ï¼‰
    _api_max_requests_per_minute: Dict[str, int] = {
        "daily": 800,
        "index_weight": 500,
        # ...
    }

    # å¹¶å‘é™åˆ¶ï¼ˆæŒ‰APIåˆ†ç±»ï¼‰
    _api_concurrency_limits: Dict[str, int] = {
        "daily": 80,
        "index_weight": 50,
        # ...
    }

    async def query(self, api_name: str, fields: List[str], **params):
        """æ‰§è¡ŒAPIæŸ¥è¯¢ï¼ˆå«é€Ÿç‡é™åˆ¶å’Œåˆ†é¡µï¼‰"""
        await self._wait_for_rate_limit_slot(api_name)
        # ... åˆ†é¡µå¤„ç† + HTTPè¯·æ±‚
```

---

### C. æ•°æ®å¤„ç†å™¨ï¼ˆprocessors/ï¼‰

#### ProcessorTaskï¼ˆæŠ½è±¡åŸºç±»ï¼‰
```python
class ProcessorTask(BaseTask, BlockProcessorMixin):
    """æ•°æ®å¤„ç†ä»»åŠ¡åŸºç±»"""

    source_tables: List[str] = []      # æºæ•°æ®è¡¨
    dependencies: List[str] = []       # ä¾èµ–çš„å…¶ä»–ä»»åŠ¡
    batch_size = 1000                  # æ‰¹å¤„ç†å¤§å°

    async def fetch_data(self, stop_event=None, **kwargs):
        """ä»æ•°æ®åº“è·å–æ•°æ®ï¼ˆå•è¡¨æˆ–å¤šè¡¨ï¼‰"""
        if len(self.source_tables) == 1:
            return await self._fetch_single_table(**kwargs)
        else:
            return await self._fetch_multiple_tables(**kwargs)

    @abstractmethod
    def _calculate_from_single_source(self, data: pd.DataFrame, **kwargs):
        """å•è¡¨æ•°æ®è®¡ç®—é€»è¾‘ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass
```

#### BlockProcessorMixinï¼ˆåˆ†å—å¤„ç†ï¼‰
```python
class BlockProcessorMixin(ABC):
    """å¤§æ•°æ®é›†åˆ†å—å¤„ç†Mixin"""
    is_block_processor: bool = False

    @abstractmethod
    def get_data_blocks(self, **kwargs) -> Iterator[Dict[str, Any]]:
        """å°†ä»»åŠ¡åˆ†è§£æˆå¯ç‹¬ç«‹å¤„ç†çš„æ•°æ®å—"""
        pass

    @abstractmethod
    def process_block(self, block_params: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """å¤„ç†å•ä¸ªæ•°æ®å—"""
        pass

    def run_all_blocks(self, **kwargs) -> None:
        """é©±åŠ¨æ‰€æœ‰æ•°æ®å—å¤„ç†"""
        for block_params in self.get_data_blocks(**kwargs):
            self.process_block(block_params)
```

#### OperationPipelineï¼ˆæ“ä½œæµæ°´çº¿ï¼‰
```python
class OperationPipeline:
    """å¯ç»„åˆçš„æ•°æ®å¤„ç†æ“ä½œæµæ°´çº¿"""

    def __init__(self, name: str = "Pipeline"):
        self.operations = []

    def add_operation(self, operation: Operation, condition=None):
        """æ·»åŠ æ“ä½œåˆ°æµæ°´çº¿ï¼ˆæ”¯æŒæ¡ä»¶æ‰§è¡Œï¼‰"""
        self.operations.append((operation, condition))
        return self

    async def apply(self, data: pd.DataFrame) -> pd.DataFrame:
        """æŒ‰é¡ºåºåº”ç”¨æ‰€æœ‰æ“ä½œ"""
        result = data.copy()
        for operation, condition in self.operations:
            if condition is None or condition(result):
                result = await operation.apply(result)
        return result
```

---

## ğŸ”Œ ä½¿ç”¨ç¤ºä¾‹

### 1. æ•°æ®é‡‡é›†ä»»åŠ¡ï¼ˆç®€å•æ¨¡å¼ - å‘åå…¼å®¹ï¼‰
```python
from data.collectors.sources.tushare import Run

# ä½¿ç”¨æ—§ç‰ˆç®€åŒ–æ¥å£
runner = Run(token="your_token")

# ä¸‹è½½æ•°æ®
runner.download(
    source_dir="~/.qlib/stock_data/source/tushare",
    start_date="20200101",
    end_date="20231231"
)

# æ ‡å‡†åŒ–æ•°æ®
runner.normalize(
    source_dir="~/.qlib/stock_data/source/tushare",
    normalize_dir="~/.qlib/stock_data/normalized/tushare"
)
```

### 2. æ•°æ®é‡‡é›†ä»»åŠ¡ï¼ˆé«˜çº§æ¨¡å¼ - æ–°ä»»åŠ¡ç³»ç»Ÿï¼‰
```python
from data.collectors.tasks.stock import StockDailyBarTask
from data.common.task_system import UnifiedTaskFactory

# æ–¹å¼1ï¼šç›´æ¥å®ä¾‹åŒ–
task = StockDailyBarTask(token="your_token")
await task.execute(
    start_date="20230101",
    end_date="20231231",
    symbols=["000001.SZ", "000002.SZ"],
    update_type="SMART"  # æ™ºèƒ½å¢é‡æ›´æ–°
)

# æ–¹å¼2ï¼šé€šè¿‡å·¥å‚è·å–
task = UnifiedTaskFactory.get_task("stock_daily_bar")
await task.execute(...)
```

### 3. æ•°æ®å¤„ç†ä»»åŠ¡ï¼ˆæ“ä½œæµæ°´çº¿ï¼‰
```python
from data.processors.operations import (
    FillNAOperation,
    MovingAverageOperation,
    RSIOperation
)
from data.processors.operations.base_operation import OperationPipeline

# åˆ›å»ºæ“ä½œæµæ°´çº¿
pipeline = OperationPipeline("è‚¡ç¥¨æ—¥çº¿å¤„ç†")

# æ·»åŠ æ“ä½œ
pipeline.add_operation(
    FillNAOperation(method='mean', columns=['close', 'volume'])
).add_operation(
    MovingAverageOperation(window=5, column='close', group_by=['ts_code'])
).add_operation(
    RSIOperation(window=14, column='close', group_by=['ts_code'])
)

# åº”ç”¨æµæ°´çº¿
import pandas as pd
data = pd.read_csv("stock_data.csv")
processed_data = await pipeline.apply(data)
```

### 4. æ•°æ®å¤„ç†ä»»åŠ¡ï¼ˆå®Œæ•´ä»»åŠ¡ï¼‰
```python
from data.processors.tasks.stock import StockAdjustedPriceTask

# å®ä¾‹åŒ–ä»»åŠ¡
task = StockAdjustedPriceTask(db_connection=db)

# æ‰§è¡Œä»»åŠ¡ï¼ˆè‡ªåŠ¨å¤„ç†å¤šè¡¨è”åˆæŸ¥è¯¢ã€è®¡ç®—ã€éªŒè¯ã€ä¿å­˜ï¼‰
result = await task.execute(
    start_date="20230101",
    end_date="20231231",
    ts_code="000001.SZ"
)
```

### 5. åˆ†å—å¤„ç†ä»»åŠ¡ï¼ˆå¤§æ•°æ®é›†ï¼‰
```python
from data.processors.tasks.stock import StockAdjdailyProcessorTask

# åˆå§‹åŒ–åˆ†å—å¤„ç†ä»»åŠ¡
task = StockAdjdailyProcessorTask(
    db_connection=db,
    config={
        "block_size_codes": 20,  # æ¯æ¬¡å¤„ç†20åªè‚¡ç¥¨
        "calendar_exchange": "SSE"
    }
)

# æ‰§è¡Œä»»åŠ¡ï¼ˆè‡ªåŠ¨åˆ†å—ã€å¹¶è¡Œå¤„ç†ã€è¿›åº¦è·Ÿè¸ªï¼‰
await task.execute(
    codes=all_stock_codes,  # æ•°åƒåªè‚¡ç¥¨
    start_date="20200101",
    end_date="20231231"
)
```

---

## ğŸ”€ è¿ç§»è·¯å¾„

### é˜¶æ®µ1ï¼šå…±å­˜é˜¶æ®µï¼ˆå½“å‰ï¼‰
- âœ… ä¿ç•™æ—§ç‰ˆæ¥å£ï¼š`base_collector.py`, `tushare_collector.py`, `normalizer.py`, `validator.py`
- âœ… æ–°å¢ä»»åŠ¡ç³»ç»Ÿï¼š`fetcher_task.py`, `processor_task.py`, `task_system.py`
- âœ… ä¸¤å¥—ç³»ç»Ÿç‹¬ç«‹è¿è¡Œï¼Œä¸ç›¸äº’ä¾èµ–

### é˜¶æ®µ2ï¼šéƒ¨åˆ†è¿ç§»
- ğŸ”„ æ–°åŠŸèƒ½ä½¿ç”¨æ–°ä»»åŠ¡ç³»ç»Ÿ
- ğŸ”„ æ—§ä»£ç é€æ­¥é‡æ„ä¸ºä»»åŠ¡
- ğŸ”„ å…³é”®ä¸šåŠ¡é€»è¾‘ä¼˜å…ˆè¿ç§»

### é˜¶æ®µ3ï¼šå®Œå…¨è¿ç§»
- â³ æ‰€æœ‰é‡‡é›†å’Œå¤„ç†é€»è¾‘ä½¿ç”¨ä»»åŠ¡ç³»ç»Ÿ
- â³ æ—§ç‰ˆæ¥å£æ ‡è®°ä¸º `@deprecated`
- â³ æä¾›è‡ªåŠ¨åŒ–è¿ç§»å·¥å…·

---

## âœ¨ æ–°æ¶æ„çš„ä¼˜åŠ¿

### 1. **å¹¶å‘æ€§èƒ½**
- AsyncIOå¹¶å‘ï¼šå•è¿›ç¨‹å¤„ç†å¤§é‡I/Oå¯†é›†ä»»åŠ¡
- æ™ºèƒ½é€Ÿç‡é™åˆ¶ï¼šé¿å…APIé™æµ
- æ‰¹é‡å¤„ç†ï¼šå‡å°‘ç½‘ç»œå¾€è¿”

### 2. **å¯é æ€§**
- è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼šç½‘ç»œæŠ–åŠ¨è‡ªåŠ¨æ¢å¤
- æ–­ç‚¹ç»­ä¼ ï¼šæ”¯æŒSMARTå¢é‡æ›´æ–°
- é”™è¯¯éš”ç¦»ï¼šå•ä¸ªæ‰¹æ¬¡å¤±è´¥ä¸å½±å“æ•´ä½“

### 3. **å¯æ‰©å±•æ€§**
- ç»Ÿä¸€æ³¨å†Œç³»ç»Ÿï¼šæ–°ä»»åŠ¡åªéœ€æ·»åŠ è£…é¥°å™¨
- ä»»åŠ¡ä¾èµ–ç®¡ç†ï¼šè‡ªåŠ¨æ£€æŸ¥å‰ç½®ä»»åŠ¡
- å¯ç»„åˆæ“ä½œï¼šçµæ´»æ„å»ºæ•°æ®å¤„ç†æµæ°´çº¿

### 4. **å¯ç»´æŠ¤æ€§**
- æ¸…æ™°çš„èŒè´£åˆ†ç¦»ï¼šé‡‡é›†å™¨ vs å¤„ç†å™¨
- ç»Ÿä¸€çš„ä»£ç é£æ ¼ï¼šæ‰€æœ‰ä»»åŠ¡ç»§æ‰¿è‡ªåŸºç±»
- å®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿï¼šè¯¦ç»†çš„æ‰§è¡Œè¿½è¸ª

### 5. **å‘åå…¼å®¹**
- æ—§ä»£ç ç»§ç»­è¿è¡Œï¼šæ— éœ€ç«‹å³è¿ç§»
- æ¸è¿›å¼å‡çº§ï¼šæŒ‰éœ€è¿ç§»å…³é”®è·¯å¾„
- ç»Ÿä¸€æ¥å£ï¼šæ–°æ—§ç³»ç»Ÿå¯äº’æ“ä½œ

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **åˆ›å»ºç›®å½•ç»“æ„**ï¼šæŒ‰ç…§ä¸Šè¿°è®¾è®¡åˆ›å»ºæ‰€æœ‰æ–‡ä»¶å¤¹
2. **å®ç°é€šç”¨ç»„ä»¶**ï¼š`task_system.py`, `logging_utils.py`, `db_manager.py`
3. **è¿ç§»ç¬¬ä¸€ä¸ªä»»åŠ¡**ï¼šå°† `tushare_collector.py` é‡æ„ä¸º `TushareTask`
4. **ç¼–å†™ä½¿ç”¨æ–‡æ¡£**ï¼šè¯¦ç»†çš„APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
5. **å•å…ƒæµ‹è¯•**ï¼šä¸ºæ‰€æœ‰æ ¸å¿ƒç»„ä»¶ç¼–å†™æµ‹è¯•

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **alphaHomeé¡¹ç›®**ï¼š`D:\2025_project\99_quantify\99_github\tushareé¡¹ç›®\alphaHome\`
- **Qlibå®˜æ–¹æ–‡æ¡£**ï¼šhttps://qlib.readthedocs.io/
- **Tushareæ–‡æ¡£**ï¼š`doc/Tushareæ•°æ®è·å–å®Œæ•´æ•™ç¨‹.md`
