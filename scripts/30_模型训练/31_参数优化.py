"""
LightGBMå‚æ•°ä¼˜åŒ–è„šæœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰
åŸºäºQlibå®˜æ–¹æœ€ä½³å®è·µ + Bayesian Optimization

æ”¹è¿›ç‚¹ï¼š
1. ä¿®å¤è·¯å¾„é—®é¢˜ï¼ˆæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.pathï¼‰
2. ä½¿ç”¨å®˜æ–¹æ¨èçš„å‚æ•°èŒƒå›´
3. ä¼˜åŒ–ICè®¡ç®—æ–¹æ³•
4. æ·»åŠ æ›´è¯¦ç»†çš„ç»“æœåˆ†æ
5. æ”¯æŒç›´æ¥ç”Ÿæˆå¯ç”¨çš„YAMLé…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/å‚æ•°ä¼˜åŒ–_æ”¹è¿›ç‰ˆ.py --n-iter 30
    python scripts/å‚æ•°ä¼˜åŒ–_æ”¹è¿›ç‰ˆ.py --n-iter 50 --instruments csi500

ä½œè€…ï¼šåŸºäºQlibå®˜æ–¹å®è·µæ”¹è¿›
æ—¥æœŸï¼š2025-11-16
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any
import yaml

# Qlib
import qlib
from qlib.contrib.model.gbdt import LGBModel
from qlib.data.dataset import DatasetH
from qlib.utils import init_instance_by_config

# è´å¶æ–¯ä¼˜åŒ–
try:
    from bayes_opt import BayesianOptimization
    BAYES_OPT_AVAILABLE = True
except ImportError:
    print("[ERROR] bayesian-optimizationæœªå®‰è£…")
    print("   è¯·è¿è¡Œ: pip install bayesian-optimization")
    BAYES_OPT_AVAILABLE = False


class ImprovedLightGBMOptimizer:
    """æ”¹è¿›ç‰ˆLightGBMå‚æ•°ä¼˜åŒ–å™¨ï¼ˆåŸºäºQlibå®˜æ–¹å®è·µï¼‰"""

    def __init__(
        self,
        config_path=None,  # é…ç½®æ–‡ä»¶è·¯å¾„(YAMLæ ¼å¼)ã€‚å¦‚æŒ‡å®š,åˆ™ä»ä¸­è¯»å–handleré…ç½®
        instruments='csi300',
        train_start='2008-01-01',
        train_end='2014-12-31',
        valid_start='2015-01-01',
        valid_end='2016-12-31'
    ):
        self.config_path = config_path
        self.instruments = instruments
        self.train_start = train_start
        self.train_end = train_end
        self.valid_start = valid_start
        self.valid_end = valid_end
        self.dataset = None
        self.best_params = None
        self.best_score = None
        self.optimization_history = []
        self.handler_config = None  # ä¿å­˜ä»YAMLè¯»å–çš„handleré…ç½®æˆ–é»˜è®¤Alpha158é…ç½®

    def load_dataset(self):
        """
        åŠ è½½æ•°æ®é›†

        åŠ è½½é€»è¾‘:
        1. å¦‚æœæŒ‡å®šäº†config_path,ä»YAMLé…ç½®æ–‡ä»¶è¯»å–handleré…ç½®
        2. å¦‚æœæœªæŒ‡å®šconfig_path,ä½¿ç”¨é»˜è®¤çš„Alpha158é…ç½®(å‘åå…¼å®¹)
        3. ä½¿ç”¨Qlibçš„init_instance_by_configè‡ªåŠ¨è¯†åˆ«handlerç±»å‹å¹¶åˆå§‹åŒ–
        """
        print("åŠ è½½æ•°æ®é›†...")

        # å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶,ä»ä¸­è¯»å–handleré…ç½®
        if self.config_path:
            print(f"ä»é…ç½®æ–‡ä»¶è¯»å–handler: {self.config_path}")

            # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(self.config_path).exists():
                raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")

            # è¯»å–YAMLé…ç½®
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)

            # æå–handleré…ç½®(å®Œæ•´çš„handlerå®šä¹‰)
            self.handler_config = config['task']['dataset']['kwargs']['handler']

            # æ›´æ–°instruments(ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼,ä¼˜å…ˆçº§é«˜äºå‘½ä»¤è¡Œå‚æ•°)
            if 'instruments' in self.handler_config['kwargs']:
                self.instruments = self.handler_config['kwargs']['instruments']
                print(f"  ä½¿ç”¨é…ç½®ä¸­çš„è‚¡ç¥¨æ± : {self.instruments}")

            print(f"  Handlerç±»å‹: {self.handler_config['class']}")

        else:
            # é»˜è®¤ä½¿ç”¨Alpha158(å‘åå…¼å®¹)
            print("æœªæŒ‡å®šé…ç½®æ–‡ä»¶,ä½¿ç”¨é»˜è®¤Alpha158 handler")
            self.handler_config = {
                'class': 'Alpha158',
                'module_path': 'qlib.contrib.data.handler',
                'kwargs': {
                    'instruments': self.instruments,
                    'start_time': '2008-01-01',
                    'end_time': '2025-11-14',        # æ›´æ–°ä¸ºæœ€æ–°æ•°æ®æ—¥æœŸ
                    'fit_start_time': '2015-01-01',  # æ›´æ–°æ‹Ÿåˆå¼€å§‹æ—¶é—´
                    'fit_end_time': '2022-12-31',    # é¿å…æµ‹è¯•æœŸæ³„æ¼
                    'infer_processors': [
                        {
                            'class': 'RobustZScoreNorm',
                            'kwargs': {'fields_group': 'feature', 'clip_outlier': True}
                        },
                        {'class': 'Fillna', 'kwargs': {'fields_group': 'feature'}}
                    ],
                    'learn_processors': [
                        {'class': 'DropnaLabel'},
                        {'class': 'CSRankNorm', 'kwargs': {'fields_group': 'label'}}
                    ],
                    'label': ['Ref($close, -2) / Ref($close, -1) - 1']
                }
            }

        # æ„å»ºdataseté…ç½®(ä½¿ç”¨è¯»å–çš„æˆ–é»˜è®¤çš„handleré…ç½®)
        dataset_config = {
            'class': 'DatasetH',
            'module_path': 'qlib.data.dataset',
            'kwargs': {
                'handler': self.handler_config,  # ä½¿ç”¨ä»YAMLè¯»å–çš„é…ç½®æˆ–é»˜è®¤Alpha158
                'segments': {
                    'train': (self.train_start, self.train_end),
                    'valid': (self.valid_start, self.valid_end),
                    'test': ('2017-01-01', '2020-12-31')
                }
            }
        }

        # ä½¿ç”¨Qlibçš„init_instance_by_configåˆå§‹åŒ–dataset
        # è¯¥å‡½æ•°ä¼šè‡ªåŠ¨è¯†åˆ«handlerç±»å‹(Alpha158æˆ–DataHandlerLP)å¹¶æ­£ç¡®åˆå§‹åŒ–
        self.dataset = init_instance_by_config(dataset_config)
        print("[OK] æ•°æ®é›†åŠ è½½å®Œæˆ")

    def objective_function(
        self,
        num_leaves,
        learning_rate,
        feature_fraction,
        bagging_fraction,
        max_depth,
        min_data_in_leaf
    ) -> float:
        """
        ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–ICå‡å€¼

        Returns:
            float: ICå‡å€¼ï¼ˆéªŒè¯é›†ï¼‰
        """
        # æ„å»ºå‚æ•°é…ç½®ï¼ˆå‚è€ƒQlibå®˜æ–¹æ¨èèŒƒå›´ï¼‰
        params = {
            'num_leaves': int(num_leaves),
            'learning_rate': learning_rate,
            'feature_fraction': feature_fraction,
            'bagging_fraction': bagging_fraction,
            'max_depth': int(max_depth),
            'min_data_in_leaf': int(min_data_in_leaf),
            # å›ºå®šå‚æ•°ï¼ˆæ¥è‡ªQlibå®˜æ–¹é…ç½®ï¼‰
            'loss': 'mse',
            'colsample_bytree': 0.8879,
            'subsample': 0.8789,
            'lambda_l1': 205.6999,
            'lambda_l2': 580.9768,
            'num_threads': 20,
            'verbosity': -1
        }

        try:
            # è®­ç»ƒæ¨¡å‹
            model = LGBModel(**params)
            model.fit(self.dataset)

            # åœ¨éªŒè¯é›†ä¸Šé¢„æµ‹
            pred = model.predict(self.dataset, segment='valid')
            label = self.dataset.prepare('valid', col_set='label')

            # è®¡ç®—ICï¼ˆInformation Coefficientï¼‰
            merged = pd.concat([label, pred], axis=1, sort=True).reindex(label.index)
            if isinstance(merged.columns, pd.MultiIndex):
                merged.columns = ['label', 'score']
            else:
                merged.columns = ['label', 'score']

            # è®¡ç®—æ¯æ—¥IC
            ic_series = merged.groupby(level=0).apply(
                lambda x: x['label'].corr(x['score'])
            )
            ic_mean = ic_series.mean()
            ic_std = ic_series.std()
            ic_ir = ic_mean / ic_std if ic_std > 0 else 0  # IC Information Ratio

            # è®°å½•å†å²
            self.optimization_history.append({
                'iteration': len(self.optimization_history) + 1,
                'num_leaves': int(num_leaves),
                'learning_rate': learning_rate,
                'feature_fraction': feature_fraction,
                'bagging_fraction': bagging_fraction,
                'max_depth': int(max_depth),
                'min_data_in_leaf': int(min_data_in_leaf),
                'ic_mean': ic_mean,
                'ic_std': ic_std,
                'ic_ir': ic_ir
            })

            print(f"  è¿­ä»£ {len(self.optimization_history)}: ICå‡å€¼={ic_mean:.4f}, IC_IR={ic_ir:.2f} | "
                  f"num_leaves={int(num_leaves)}, lr={learning_rate:.3f}")

            return ic_mean

        except Exception as e:
            print(f"[WARNING] è®­ç»ƒå¤±è´¥: {e}")
            return -1.0

    def optimize(self, n_iter=30, init_points=5) -> Dict[str, Any]:
        """
        æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–

        Args:
            n_iter: ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
            init_points: åˆå§‹éšæœºæ¢ç´¢ç‚¹æ•°

        Returns:
            dict: æœ€ä¼˜å‚æ•°
        """
        if not BAYES_OPT_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£…bayesian-optimization: pip install bayesian-optimization")

        if self.dataset is None:
            self.load_dataset()

        print("\n" + "="*80)
        print("LightGBMå‚æ•°ä¼˜åŒ–ï¼ˆæ”¹è¿›ç‰ˆ - åŸºäºQlibå®˜æ–¹å®è·µï¼‰")
        print("="*80)
        print(f"ä¼˜åŒ–ç›®æ ‡: æœ€å¤§åŒ–ICå‡å€¼ï¼ˆéªŒè¯é›†{self.valid_start}è‡³{self.valid_end}ï¼‰")
        print(f"ä¼˜åŒ–æ–¹æ³•: è´å¶æ–¯ä¼˜åŒ–ï¼ˆGaussian Processï¼‰")
        print(f"è‚¡ç¥¨æ± : {self.instruments}")
        print(f"è¿­ä»£æ¬¡æ•°: {n_iter}")
        print(f"åˆå§‹æ¢ç´¢: {init_points}\n")

        # å®šä¹‰å‚æ•°ç©ºé—´ï¼ˆå‚è€ƒQlibå®˜æ–¹æ¨èèŒƒå›´ï¼‰
        pbounds = {
            'num_leaves': (20, 210),           # Qlibå®˜æ–¹ä½¿ç”¨210
            'learning_rate': (0.01, 0.3),      # Qlibå®˜æ–¹ä½¿ç”¨0.2
            'feature_fraction': (0.6, 1.0),    # ç‰¹å¾é‡‡æ ·ç‡
            'bagging_fraction': (0.6, 1.0),    # æ ·æœ¬é‡‡æ ·ç‡
            'max_depth': (3, 10),              # Qlibå®˜æ–¹ä½¿ç”¨8
            'min_data_in_leaf': (10, 100)      # å¶å­æœ€å°æ ·æœ¬æ•°
        }

        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = BayesianOptimization(
            f=self.objective_function,
            pbounds=pbounds,
            random_state=42,
            verbose=0
        )

        # æ‰§è¡Œä¼˜åŒ–
        print("å¼€å§‹ä¼˜åŒ–...")
        optimizer.maximize(
            init_points=init_points,
            n_iter=n_iter
        )

        # æå–æœ€ä¼˜å‚æ•°
        best_params = optimizer.max['params']
        best_params['num_leaves'] = int(best_params['num_leaves'])
        best_params['max_depth'] = int(best_params['max_depth'])
        best_params['min_data_in_leaf'] = int(best_params['min_data_in_leaf'])

        self.best_params = best_params
        self.best_score = optimizer.max['target']

        print("\n" + "="*80)
        print("ä¼˜åŒ–å®Œæˆï¼")
        print("="*80)
        print(f"\nğŸ† æœ€ä¼˜ICå‡å€¼: {self.best_score:.4f}")
        print(f"\nğŸ“‹ æœ€ä¼˜å‚æ•°ï¼š")
        for param, value in best_params.items():
            print(f"   - {param}: {value}")

        # æ‰¾åˆ°æœ€ä¼˜å‚æ•°å¯¹åº”çš„IC_IR
        best_record = [r for r in self.optimization_history if r['ic_mean'] == self.best_score]
        if best_record:
            print(f"\nğŸ“Š æœ€ä¼˜å‚æ•°çš„å…¶ä»–æŒ‡æ ‡ï¼š")
            print(f"   - ICæ ‡å‡†å·®: {best_record[0]['ic_std']:.4f}")
            print(f"   - ICä¿¡æ¯æ¯”ç‡: {best_record[0]['ic_ir']:.2f}")

        return best_params

    def save_results(self, output_path=None) -> None:
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        if output_path is None:
            project_root = Path(__file__).parent.parent
            output_path = project_root / 'docs' / 'lightgbm_optimization_results_improved.txt'

        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("LightGBMå‚æ•°ä¼˜åŒ–ç»“æœï¼ˆæ”¹è¿›ç‰ˆ - åŸºäºQlibå®˜æ–¹å®è·µï¼‰\n")
            f.write("="*80 + "\n\n")

            f.write(f"ä¼˜åŒ–æ—¶é—´: {datetime.now()}\n")
            f.write(f"è‚¡ç¥¨æ± : {self.instruments}\n")
            f.write(f"éªŒè¯é›†: {self.valid_start} ~ {self.valid_end}\n")
            f.write(f"ä¼˜åŒ–è¿­ä»£: {len(self.optimization_history)}\n\n")

            f.write(f"ğŸ† æœ€ä¼˜ICå‡å€¼: {self.best_score:.4f}\n\n")

            # æ‰¾åˆ°æœ€ä¼˜è®°å½•
            best_record = [r for r in self.optimization_history if r['ic_mean'] == self.best_score]
            if best_record:
                f.write(f"ğŸ“Š æœ€ä¼˜å‚æ•°çš„è¯¦ç»†æŒ‡æ ‡ï¼š\n")
                f.write(f"   - ICå‡å€¼: {best_record[0]['ic_mean']:.4f}\n")
                f.write(f"   - ICæ ‡å‡†å·®: {best_record[0]['ic_std']:.4f}\n")
                f.write(f"   - ICä¿¡æ¯æ¯”ç‡: {best_record[0]['ic_ir']:.2f}\n\n")

            f.write("ğŸ“‹ æœ€ä¼˜å‚æ•°é…ç½®ï¼ˆå¯ç›´æ¥å¤åˆ¶åˆ°YAMLï¼‰ï¼š\n")
            f.write("```yaml\n")
            f.write("task:\n")
            f.write("  model:\n")
            f.write("    class: LGBModel\n")
            f.write("    module_path: qlib.contrib.model.gbdt\n")
            f.write("    kwargs:\n")
            f.write("      loss: mse\n")
            f.write("      colsample_bytree: 0.8879\n")
            f.write("      subsample: 0.8789\n")
            f.write("      lambda_l1: 205.6999\n")
            f.write("      lambda_l2: 580.9768\n")
            for param, value in self.best_params.items():
                f.write(f"      {param}: {value}\n")
            f.write("      num_threads: 20\n")
            f.write("```\n\n")

            # ä¼˜åŒ–å†å²ï¼ˆTop 10ï¼‰
            history_df = pd.DataFrame(self.optimization_history)
            history_df = history_df.sort_values('ic_mean', ascending=False)

            f.write("ğŸ“Š ä¼˜åŒ–å†å²ï¼ˆTop 10ï¼‰ï¼š\n")
            f.write(history_df.head(10).to_string(index=False))
            f.write("\n\n")

            f.write("="*80 + "\n")

        print(f"\n[OK] ä¼˜åŒ–ç»“æœå·²ä¿å­˜è‡³: {output_path}")

        # åŒæ—¶ä¿å­˜ä¸ºCSV
        csv_path = output_path.parent / output_path.name.replace('.txt', '.csv')
        history_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"[OK] ä¼˜åŒ–å†å²å·²ä¿å­˜è‡³: {csv_path}")

        # ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„YAMLé…ç½®æ–‡ä»¶
        # å¦‚æœæŒ‡å®šäº†config_path,ç”ŸæˆåŸºäºåŸé…ç½®æ–‡ä»¶åçš„ä¼˜åŒ–ç‰ˆæœ¬
        if self.config_path:
            base_name = Path(self.config_path).stem
            yaml_path = output_path.parent.parent / 'configs' / f'{base_name}_optimized.yaml'
        else:
            yaml_path = output_path.parent.parent / 'configs' / f'workflow_config_optimized_{self.instruments}.yaml'

        self.generate_yaml_config(yaml_path)

    def generate_yaml_config(self, yaml_path):
        """
        ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„YAMLé…ç½®æ–‡ä»¶

        ç”Ÿæˆé€»è¾‘:
        1. å¦‚æœæŒ‡å®šäº†config_path,åŸºäºåŸå§‹é…ç½®æ–‡ä»¶ç”Ÿæˆ(ä¿ç•™handleré…ç½®)
        2. å¦‚æœæœªæŒ‡å®šconfig_path,ç”Ÿæˆé»˜è®¤Alpha158é…ç½®
        3. æ›´æ–°æ¨¡å‹å‚æ•°ä¸ºä¼˜åŒ–åçš„æœ€ä¼˜å‚æ•°
        """
        yaml_path = Path(yaml_path)
        yaml_path.parent.mkdir(parents=True, exist_ok=True)

        # å°†NumPyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹(é¿å…YAMLåºåˆ—åŒ–é—®é¢˜)
        best_params_native = {}
        for key, value in self.best_params.items():
            if isinstance(value, np.integer):
                best_params_native[key] = int(value)
            elif isinstance(value, np.floating):
                best_params_native[key] = float(value)
            else:
                best_params_native[key] = value

        # å¦‚æœæŒ‡å®šäº†åŸå§‹é…ç½®æ–‡ä»¶,åŸºäºå®ƒç”Ÿæˆä¼˜åŒ–ç‰ˆæœ¬
        if self.config_path:
            print(f"åŸºäºé…ç½®æ–‡ä»¶ç”Ÿæˆä¼˜åŒ–ç‰ˆæœ¬: {self.config_path}")

            # è¯»å–åŸå§‹é…ç½®
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)

            # æ›´æ–°æ¨¡å‹å‚æ•°(ä¿ç•™åŸæœ‰handleré…ç½®)
            config['task']['model']['kwargs'].update(best_params_native)
            config['task']['model']['kwargs']['num_threads'] = 20

        else:
            # ç”Ÿæˆé»˜è®¤Alpha158é…ç½®
            print("ç”Ÿæˆé»˜è®¤Alpha158é…ç½®")
            config = {
                'qlib_init': {
                    'provider_uri': 'D:/Data/my_stock',
                    'region': 'cn'
                },
                'market': self.instruments,
                'benchmark': 'SH000300' if self.instruments == 'csi300' else 'SH000905',
                'data_handler_config': {
                    'start_time': '2008-01-01',
                    'end_time': '2025-11-14',        # æ›´æ–°ä¸ºæœ€æ–°æ•°æ®æ—¥æœŸ
                    'fit_start_time': '2015-01-01',  # æ›´æ–°æ‹Ÿåˆå¼€å§‹æ—¶é—´
                    'fit_end_time': '2022-12-31',    # é¿å…æµ‹è¯•æœŸæ³„æ¼
                    'instruments': self.instruments
                },
                'port_analysis_config': {
                    'strategy': {
                        'class': 'TopkDropoutStrategy',
                        'module_path': 'qlib.contrib.strategy',
                        'kwargs': {
                            'signal': '<PRED>',
                            'topk': 50,
                            'n_drop': 5
                        }
                    },
                    'backtest': {
                        'start_time': '2025-01-01',  # å›æµ‹ä½¿ç”¨æœ€æ–°ä¸€å¹´
                        'end_time': '2025-11-14',    # æ›´æ–°ä¸ºæœ€æ–°æ•°æ®æ—¥æœŸ
                        'account': 100000000,
                        'benchmark': 'SH000300' if self.instruments == 'csi300' else 'SH000905',
                        'exchange_kwargs': {
                            'limit_threshold': 0.095,
                            'deal_price': 'close',
                            'open_cost': 0.0005,
                            'close_cost': 0.0015,
                            'min_cost': 5
                        }
                    }
                },
                'task': {
                    'model': {
                        'class': 'LGBModel',
                        'module_path': 'qlib.contrib.model.gbdt',
                        'kwargs': {
                            'loss': 'mse',
                            'colsample_bytree': 0.8879,
                            'subsample': 0.8789,
                            'lambda_l1': 205.6999,
                            'lambda_l2': 580.9768,
                            **best_params_native,
                            'num_threads': 20
                        }
                    },
                    'dataset': {
                        'class': 'DatasetH',
                        'module_path': 'qlib.data.dataset',
                        'kwargs': {
                            'handler': self.handler_config,  # ä½¿ç”¨ä¿å­˜çš„handleré…ç½®
                            'segments': {
                                'train': ['2015-01-01', '2022-12-31'],  # 8å¹´è®­ç»ƒæœŸ
                                'valid': ['2023-01-01', '2024-12-31'],  # 2å¹´éªŒè¯æœŸ
                                'test': ['2025-01-01', '2025-11-14']    # æœ€æ–°å¹´ä»½æµ‹è¯•
                            }
                        }
                    },
                    'record': [
                        {
                            'class': 'SignalRecord',
                            'module_path': 'qlib.workflow.record_temp',
                            'kwargs': {}
                        },
                        {
                            'class': 'SigAnaRecord',
                            'module_path': 'qlib.workflow.record_temp',
                            'kwargs': {
                                'ana_long_short': False,
                                'ann_scaler': 252
                            }
                        },
                        {
                            'class': 'PortAnaRecord',
                            'module_path': 'qlib.workflow.record_temp',
                            'kwargs': {
                                'config': '<PORT_ANALYSIS_CONFIG>'
                            }
                        }
                    ]
                }
            }

        # ä¿å­˜é…ç½®åˆ°YAMLæ–‡ä»¶
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, allow_unicode=True, sort_keys=False)

        print(f"[OK] å·²ç”Ÿæˆå¯ç”¨é…ç½®æ–‡ä»¶: {yaml_path}")
        print(f"\nğŸ’¡ å¯ç›´æ¥è¿è¡Œ: python scripts/30_è¿è¡Œå·¥ä½œæµ.py {yaml_path}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description='LightGBMå‚æ•°ä¼˜åŒ–(æ”¯æŒä»»æ„é…ç½®æ–‡ä»¶)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ–¹å¼1: ä¼˜åŒ–Alpha158å› å­(é»˜è®¤,å‘åå…¼å®¹)
  python scripts/å‚æ•°ä¼˜åŒ–_æ”¹è¿›ç‰ˆ.py --n-iter 30

  # æ–¹å¼2: ä¼˜åŒ–Top50å› å­
  python scripts/å‚æ•°ä¼˜åŒ–_æ”¹è¿›ç‰ˆ.py --config configs/workflow_config_top50.yaml --n-iter 30

  # æ–¹å¼3: ä¼˜åŒ–è‡ªå®šä¹‰é…ç½®
  python scripts/å‚æ•°ä¼˜åŒ–_æ”¹è¿›ç‰ˆ.py --config configs/my_custom_config.yaml --n-iter 50
        """
    )
    parser.add_argument(
        '--config',
        type=str,
        default=None,
        help='é…ç½®æ–‡ä»¶è·¯å¾„(YAMLæ ¼å¼)ã€‚å¦‚ä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤Alpha158é…ç½®'
    )
    parser.add_argument('--n-iter', type=int, default=30, help='ä¼˜åŒ–è¿­ä»£æ¬¡æ•°(é»˜è®¤30)')
    parser.add_argument('--init-points', type=int, default=5, help='åˆå§‹éšæœºæ¢ç´¢ç‚¹æ•°(é»˜è®¤5)')
    parser.add_argument(
        '--instruments',
        type=str,
        default='csi300',
        help='è‚¡ç¥¨æ± (ä»…åœ¨ä¸æŒ‡å®š--configæ—¶æœ‰æ•ˆ,é»˜è®¤csi300)'
    )

    args = parser.parse_args()

    # åˆå§‹åŒ–Qlib
    print("åˆå§‹åŒ–Qlib...")
    qlib.init(provider_uri='D:/Data/my_stock', region='cn')
    print("[OK] Qlibåˆå§‹åŒ–å®Œæˆ\n")

    # åˆ›å»ºä¼˜åŒ–å™¨
    # ä½¿ç”¨æ›´è¿‘æœŸçš„æ•°æ®è¿›è¡Œå‚æ•°ä¼˜åŒ–ï¼š
    # - è®­ç»ƒé›†ï¼š2015-2022ï¼ˆ8å¹´ï¼Œè¦†ç›–å®Œæ•´ç‰›ç†Šå‘¨æœŸï¼‰
    # - éªŒè¯é›†ï¼š2023-2024ï¼ˆ2å¹´ï¼Œç”¨äºå‚æ•°è°ƒä¼˜ï¼‰
    optimizer = ImprovedLightGBMOptimizer(
        config_path=args.config,  # ä¼ å…¥é…ç½®æ–‡ä»¶è·¯å¾„
        instruments=args.instruments,  # å¦‚æœæœ‰config,æ­¤å‚æ•°ä¼šè¢«é…ç½®è¦†ç›–
        train_start='2015-01-01',
        train_end='2022-12-31',
        valid_start='2023-01-01',
        valid_end='2024-12-31'
    )

    # æ‰§è¡Œä¼˜åŒ–
    best_params = optimizer.optimize(
        n_iter=args.n_iter,
        init_points=args.init_points
    )

    # ä¿å­˜ç»“æœ
    optimizer.save_results()

    print("\n[OK] å‚æ•°ä¼˜åŒ–å®Œæˆ!")
    print("\nğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("   1. æŸ¥çœ‹ä¼˜åŒ–ç»“æœ: docs/lightgbm_optimization_results_improved.txt")

    # æ ¹æ®æ˜¯å¦æŒ‡å®šconfigç»™å‡ºä¸åŒçš„è¿è¡Œå»ºè®®
    if args.config:
        # ç”ŸæˆåŸºäºåŸé…ç½®çš„ä¼˜åŒ–ç‰ˆæœ¬æ–‡ä»¶å
        base_name = Path(args.config).stem
        optimized_config = f"configs/{base_name}_optimized.yaml"
        print(f"   2. ä½¿ç”¨ä¼˜åŒ–åçš„é…ç½®: python scripts/30_è¿è¡Œå·¥ä½œæµ.py {optimized_config}")
    else:
        print(f"   2. ä½¿ç”¨ä¼˜åŒ–åçš„é…ç½®: python scripts/30_è¿è¡Œå·¥ä½œæµ.py configs/workflow_config_optimized_{args.instruments}.yaml")

    print("   3. å¯¹æ¯”æ€§èƒ½æå‡\n")
